{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Libaries\n",
    "from azureml.core import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.explain.model._internal.explanation_client import ExplanationClient\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal, BayesianParameterSampling, uniform, choice\n",
    "from azureml.core import Run\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Azure Machine Learning Pipeline\n",
    "In this notebook, we will show how to prep data, train model, register model and deploy the model using AML pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Your Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.6.0 to work with ml-teaching-workspace\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve your Datasets by name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your Datasets by name\n",
    "df_name  = \"auto-mpg-classification-input\" # CHANGE HERE\n",
    "\n",
    "\n",
    "# Load Data in as Tabular Datasets\n",
    "df_tab  = Dataset.get_by_name(ws, df_name, version='latest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scripts for Pipeline Steps\n",
    "Start by creating a folder to contain the scripts for each step/task of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_mpg_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'auto_mpg_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to tranform the raw data to prepare the training dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting auto_mpg_pipeline/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/data_prep.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--clean_data\", type=str, dest='clean_data' ,help=\"output_training_data directory\")\n",
    "args = parser.parse_args()\n",
    "clean_data = args.clean_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the mpg data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "\n",
    "dataset = run.input_datasets['raw_data']\n",
    "\n",
    "# Transform the data\n",
    "\n",
    "df = dataset.to_pandas_dataframe()   \n",
    "\n",
    "# get rid of the last column as we dont gain any info from it\n",
    "df_column9_dropped = df.drop(['Column9'], axis=1)\n",
    "\n",
    "# add header row to the dataframe\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']\n",
    "df_column9_dropped.columns = column_names\n",
    "df_with_headers = df_column9_dropped\n",
    "\n",
    "# remove rows with '?' character\n",
    "\n",
    "df_with_headers = df_with_headers[df_with_headers.Horsepower != '?']\n",
    "\n",
    "# The \"Origin\" column is really categorical, not numeric. So convert that to a one-hot:\n",
    "df_with_headers['Origin'] = df_with_headers['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "\n",
    "train_dataset = pd.get_dummies(df_with_headers, columns=[\"Origin\"], prefix=[\"Origin_is\"] )\n",
    "\n",
    "\n",
    "#Separate the features from the target variable(mpg)\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "\n",
    "train_dataset[[\"Horsepower\"]] = train_dataset[[\"Horsepower\"]].apply(pd.to_numeric)\n",
    "\n",
    "## save clean dataset to be use in the nexy step (e.g. model training step)\n",
    "\n",
    "os.makedirs(clean_data, exist_ok=True)\n",
    "train_dataset_output_path = clean_data + \"/train_dataset.pkl\"\n",
    "train_labels_output_path = clean_data + \"/train_labels.pkl\"\n",
    "\n",
    "\n",
    "train_labels.to_pickle(train_labels_output_path)\n",
    "train_dataset.to_pickle(train_dataset_output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to train the model using the cleaned data from the previous step and saved the model for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting auto_mpg_pipeline/Regression_XGBoost.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/Regression_XGBoost.py\n",
    "# Load in Libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "from azureml.core import Run\n",
    "from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "from interpret.ext.glassbox import LGBMExplainableModel\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "from azureml.core.dataset import Dataset\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "run = Run.get_context()\n",
    "# Load in Arguments.  \n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--trained_model\", type=str, dest='trained_model' ,help=\"trained_model directory\")\n",
    "\n",
    "parser.add_argument('--clean_data', type=str, dest='clean_data',  help='clean_data location')\n",
    "\n",
    "args = parser.parse_args()\n",
    "# trained_model = args.trained_model\n",
    "clean_data = args.clean_data\n",
    "\n",
    "# load the training data\n",
    "\n",
    "train_data_path = clean_data + \"/train_dataset.pkl\"\n",
    "train_labels_path = clean_data + \"/train_labels.pkl\"\n",
    "\n",
    "train_dataset = pd.read_pickle(train_data_path)\n",
    "train_labels = pd.read_pickle(train_labels_path)\n",
    "\n",
    "xgb = XGBRegressor(colsample_bytree=0.6,\n",
    "             gamma=0.1,                 \n",
    "             learning_rate=0.07,\n",
    "             max_depth=5,\n",
    "             min_child_weight=6,\n",
    "             n_estimators=100,                                                                    \n",
    "             reg_alpha=0.01,\n",
    "             reg_lambda=0.45,\n",
    "             subsample=0.6,\n",
    "             seed=42,objective='reg:squarederror')\n",
    "xgb.fit(train_dataset,train_labels)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup compute cluster and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#The compute will require a Python environment with the necessary package dependencies installed, \n",
    "#so we'll create a run configuration.\n",
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# get the existing computer cluster we had created in the past\n",
    "compute_name = 'aml-cluster' \n",
    "compute_target = ComputeTarget(ws, compute_name) \n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "auto_mpg_env = Environment(\"auto-mpg-pipeline-env\")\n",
    "auto_mpg_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "auto_mpg_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "auto_mpg_packages = CondaDependencies.create(conda_packages=['scikit-learn==0.20.3', 'numpy==1.16.2','matplotlib==3.2.1',\\\n",
    "                                'joblib==0.14.1','xgboost==0.90','seaborn==0.9.0','lightgbm==2.3.0'],\n",
    "                pip_packages=['azureml-defaults==1.3.0','azureml-contrib-interpret==1.3.0',\\\n",
    "                              'azureml-explain-model==1.3.0','azureml-dataprep[pandas]==1.4.3','pyarrow==0.15.1'])\n",
    "\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "auto_mpg_env.python.conda_dependencies = auto_mpg_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "auto_mpg_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'auto-mpg-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = compute_target\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Run a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "\n",
    "\n",
    "clean_data = PipelineData(\"clean_data\", datastore=ws.get_default_datastore())\n",
    "\n",
    "\n",
    "# estimator = Estimator(source_directory=experiment_folder,\n",
    "#                         compute_target = pipeline_cluster,\n",
    "#                         environment_definition=pipeline_run_config.environment,\n",
    "#                         entry_script='train_diabetes.py')\n",
    "\n",
    "# # Step 1, run the estimator to train the model\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "clean_data_step = PythonScriptStep(name = \"Data Prep\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"data_prep.py\",\n",
    "                                arguments = ['--clean_data', clean_data],\n",
    "                                inputs=[df_tab.as_named_input('raw_data')],\n",
    "                                outputs=[clean_data],   \n",
    "                                compute_target = compute_target,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = compute_target,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='Regression_XGBoost.py')\n",
    "\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--clean_data', clean_data],\n",
    "                           inputs=[clean_data],\n",
    "#                            outputs=[model_folder],\n",
    "                           compute_target = compute_target,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "\n",
    "print(\"Pipeline steps defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now you're ready to build the pipeline from the steps you've defined and run it as an experiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Data Prep [b5031ab5][b176797d-5b33-463c-895f-9b6c6e315021], (This step will run and generate new outputs)Created step Train Model [dfa96c52][4ab0a6fa-7231-4312-9195-205b7bc09559], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun d80e081f-68db-4290-8b07-df9bb974ce92\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/auto-mpg-end-to-end-pipeline/runs/d80e081f-68db-4290-8b07-df9bb974ce92?wsid=/subscriptions/dcfc206a-203b-4c00-a236-bdf576a37896/resourcegroups/ml-teaching/workspaces/ml-teaching-workspace\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb42df5697034ff0bdcd36d4541392d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: d80e081f-68db-4290-8b07-df9bb974ce92\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/auto-mpg-end-to-end-pipeline/runs/d80e081f-68db-4290-8b07-df9bb974ce92?wsid=/subscriptions/dcfc206a-203b-4c00-a236-bdf576a37896/resourcegroups/ml-teaching/workspaces/ml-teaching-workspace\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 05d185bd-e0ca-4d7c-90f9-10c8d1075386\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/auto-mpg-end-to-end-pipeline/runs/05d185bd-e0ca-4d7c-90f9-10c8d1075386?wsid=/subscriptions/dcfc206a-203b-4c00-a236-bdf576a37896/resourcegroups/ml-teaching/workspaces/ml-teaching-workspace\n",
      "StepRun( Data Prep ) Status: NotStarted\n",
      "StepRun( Data Prep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "========================================================================================================================\n",
      "2020-06-12T03:26:01Z Starting output-watcher...\n",
      "2020-06-12T03:26:01Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-06-12T03:27:31.860726\n",
      "Starting job preparation. Current time:2020-06-12T03:27:32.605213\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 9e05daf6-7cec-4b52-b379-a67b9bfee8a9\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 51\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-12T03:27:34.566856\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/06/12 03:27:36 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-06-12T03:27:38.142598\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 105\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ data_prep.py ] with arguments: ['--clean_data', '/mnt/batch/tasks/shared/LS_root/jobs/ml-teaching-workspace/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/mounts/workspaceblobstore/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data']\n",
      "After variable expansion, calling script [ data_prep.py ] with arguments: ['--clean_data', '/mnt/batch/tasks/shared/LS_root/jobs/ml-teaching-workspace/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/mounts/workspaceblobstore/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data']\n",
      "\n",
      "Loading Data...\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-06-12T03:27:58.316148\n",
      "Starting job release. Current time:2020-06-12T03:27:59.328592\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 290\n",
      "Entering context manager injector. Current time:2020-06-12T03:27:59.348876\n",
      "Job release is complete. Current time:2020-06-12T03:28:00.939891\n",
      "\n",
      "StepRun(Data Prep) Execution Summary\n",
      "=====================================\n",
      "StepRun( Data Prep ) Status: Finished\n",
      "{'runId': '05d185bd-e0ca-4d7c-90f9-10c8d1075386', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-12T03:25:49.521601Z', 'endTimeUtc': '2020-06-12T03:28:02.896398Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '9e05daf6-7cec-4b52-b379-a67b9bfee8a9', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'b176797d-5b33-463c-895f-9b6c6e315021', 'azureml.pipelinerunid': 'd80e081f-68db-4290-8b07-df9bb974ce92', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '3841144f-7f7e-41f0-9036-3376da216189'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'data_prep.py', 'useAbsolutePath': False, 'arguments': ['--clean_data', '$AZUREML_DATAREFERENCE_clean_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'clean_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '3841144f-7f7e-41f0-9036-3376da216189', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment auto-mpg-end-to-end-pipeline Environment', 'version': 'Autosave_2020-06-11T22:24:08Z_1ee3eed4', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.6.0', 'azureml-contrib-interpret~=1.6.0', 'azureml-explain-model~=1.6.0', 'azureml-dataprep[pandas]==1.4.3', 'pyarrow==0.15.1']}, 'scikit-learn==0.20.3', 'numpy==1.16.2', 'matplotlib==3.2.1', 'joblib==0.14.1', 'xgboost==0.90', 'seaborn==0.9.0', 'lightgbm==2.3.0'], 'name': 'azureml_cd34eccd0ba5d5f69e8290f8fcd59156'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=tg7ed8v%2Ba1Vse3yxgr2iKM2pQ%2BRxucpViaIphQgOLq4%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=ojH35Gk1FjnmdmDI3H1jRVZy8Ij0h58Ms7yD%2BjMFUaI%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=S%2Br5nt9fO8kp7TmDgEGcHT2rhtyCFf11qOxWUJZlbOU%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=RXA%2FMRRuiHp%2BkVC2jAQh23TXCmutkpIav2nRtaYVelo%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'azureml-logs/process_info.json': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=RKeZRhzSSxXvEqiBL3RXVrOSDVBBRULOtkZkcgiL0o4%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'azureml-logs/process_status.json': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=e6XXZ4H4VQClJ0nGJzJy2EOyKtn1PS5Trttyidjmrl4%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/105_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/105_azureml.log?sv=2019-02-02&sr=b&sig=KahoRXUpKX6eczSfgLS526EpO8D7m5cgSetnS10AE6A%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=JPwEh9iID3XUhdQbEuM3MvizlkBQYlekAR7nEyUARAA%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=KQiYsa8vmTcv%2BE2xlPHn6CIRa%2FHzx5Bqfg9QgDrRP1g%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=ZERH1Xm9USDyUdQThpwkwVbVq0YShNCqz63DxAHBR5g%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=RSKNsNDPSkofsslaf67tRgwS34nvs5NsNbelhfBEPBA%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.05d185bd-e0ca-4d7c-90f9-10c8d1075386/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Gskli0j9ljuYKAn7Y8e0RLAhxzH%2BYob%2FUHc0X%2B7OnAw%3D&st=2020-06-12T03%3A18%3A08Z&se=2020-06-12T11%3A28%3A08Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: bd21ad66-e56f-403f-9315-2c9a0a7190d4\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/auto-mpg-end-to-end-pipeline/runs/bd21ad66-e56f-403f-9315-2c9a0a7190d4?wsid=/subscriptions/dcfc206a-203b-4c00-a236-bdf576a37896/resourcegroups/ml-teaching/workspaces/ml-teaching-workspace\n",
      "StepRun( Train Model ) Status: Queued\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "========================================================================================================================\n",
      "2020-06-12T03:28:29Z Starting output-watcher...\n",
      "2020-06-12T03:28:29Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "9dc8cf12d9c5489583399c606ed65847a7c1595829033cf9098d5c7bac501405\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-06-12T03:28:32.061108\n",
      "Starting job preparation. Current time:2020-06-12T03:28:32.956271\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 9e05daf6-7cec-4b52-b379-a67b9bfee8a9\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 49\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-12T03:28:34.837860\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/06/12 03:28:36 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-06-12T03:28:38.453134\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 109\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ Regression_XGBoost.py ] with arguments: ['--clean_data', '/mnt/batch/tasks/shared/LS_root/jobs/ml-teaching-workspace/azureml/bd21ad66-e56f-403f-9315-2c9a0a7190d4/mounts/workspaceblobstore/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data']\n",
      "After variable expansion, calling script [ Regression_XGBoost.py ] with arguments: ['--clean_data', '/mnt/batch/tasks/shared/LS_root/jobs/ml-teaching-workspace/azureml/bd21ad66-e56f-403f-9315-2c9a0a7190d4/mounts/workspaceblobstore/azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data']\n",
      "\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-06-12T03:28:46.202558\n",
      "Starting job release. Current time:2020-06-12T03:28:47.227675\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 140\n",
      "Entering context manager injector. Current time:2020-06-12T03:28:47.238731\n",
      "Job release is complete. Current time:2020-06-12T03:28:48.584959\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': 'bd21ad66-e56f-403f-9315-2c9a0a7190d4', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-12T03:28:19.66501Z', 'endTimeUtc': '2020-06-12T03:28:50.450998Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '9e05daf6-7cec-4b52-b379-a67b9bfee8a9', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '4ab0a6fa-7231-4312-9195-205b7bc09559', 'azureml.pipelinerunid': 'd80e081f-68db-4290-8b07-df9bb974ce92', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'Regression_XGBoost.py', 'useAbsolutePath': False, 'arguments': ['--clean_data', '$AZUREML_DATAREFERENCE_clean_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'clean_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/05d185bd-e0ca-4d7c-90f9-10c8d1075386/clean_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment auto-mpg-end-to-end-pipeline Environment', 'version': 'Autosave_2020-06-11T22:24:08Z_1ee3eed4', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.6.0', 'azureml-contrib-interpret~=1.6.0', 'azureml-explain-model~=1.6.0', 'azureml-dataprep[pandas]==1.4.3', 'pyarrow==0.15.1']}, 'scikit-learn==0.20.3', 'numpy==1.16.2', 'matplotlib==3.2.1', 'joblib==0.14.1', 'xgboost==0.90', 'seaborn==0.9.0', 'lightgbm==2.3.0'], 'name': 'azureml_cd34eccd0ba5d5f69e8290f8fcd59156'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/55_azureml-execution-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=OYJYBZlKpT%2FOzuwPxB%2F2HbWhfmKEU%2FB3t4DGzHS2x5o%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/65_job_prep-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=CsoDMA7A5LF2l9TpAmMXmHm7AvF3VjlD7bJoDBY76xQ%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=AXhBvwZnCCc2oxr6qpgjSFB1mXgdXHqzdf1eoDDU3mU%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/75_job_post-tvmps_8aa3614fe830113895518f8f8d274bf65f36b50b25a77ece532e9d9dfca04aa7_d.txt?sv=2019-02-02&sr=b&sig=DQOvf5QKs67D9jhxY7vBFwVBGTasxx2rpUs3pR3BuJA%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'azureml-logs/process_info.json': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=o1x5BA5%2F%2Bx%2FiD2o3iT1y2T%2Ft0ser2d7hxFrnq8otd5g%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'azureml-logs/process_status.json': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=8rsNIhiCESepoXwplPVX%2B8z8GLLeq%2BfrNo3pkNsxv4w%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/109_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=LBdPPRUtKkm8m4GQO8F68ZkVkQlxt%2FHd1I9E47Id4ug%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=NyhvjRNLbqthbxDsnocVcB0WO6HJAC9Loh1ynMNFWGo%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=VS%2BbKAHoYll2BLemvOZpsQKJ0e0Rcj%2FD4yHz7iv3O1g%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=HgZFLvcipCekIVQ46WT35wop6MpUaEtBXj2MPPMYx30%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=i3zvsYIpFfGUf2K%2FvHO1OSbXA9nH4BEnoYB1Lwb%2BYDw%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.bd21ad66-e56f-403f-9315-2c9a0a7190d4/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=DqwRAhHPy09U7yX%2FF9BHJRv%2BJuBatPayq2jZ1SjAeKI%3D&st=2020-06-12T03%3A18%3A54Z&se=2020-06-12T11%3A28%3A54Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'd80e081f-68db-4290-8b07-df9bb974ce92', 'status': 'Completed', 'startTimeUtc': '2020-06-12T03:22:55.184669Z', 'endTimeUtc': '2020-06-12T03:28:53.343107Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.d80e081f-68db-4290-8b07-df9bb974ce92/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=I4iA%2BbBott3hSwhMakob0MYveuLXb1yY57Ae8S0oHKo%3D&st=2020-06-12T03%3A18%3A55Z&se=2020-06-12T11%3A28%3A55Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.d80e081f-68db-4290-8b07-df9bb974ce92/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=yz0E%2FoShzwGZQaAOlGCKZnQsr7OHTgwZKFRKp73bfO4%3D&st=2020-06-12T03%3A18%3A55Z&se=2020-06-12T11%3A28%3A55Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlteachingwork9525397520.blob.core.windows.net/azureml/ExperimentRun/dcid.d80e081f-68db-4290-8b07-df9bb974ce92/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=BUgKqpetmcO%2Baf%2FFcwptqbmYwIbJN1BDYOWTEHbPPlQ%3D&st=2020-06-12T03%3A18%3A55Z&se=2020-06-12T11%3A28%3A55Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [clean_data_step,train_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'auto-mpg-end-to-end-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
